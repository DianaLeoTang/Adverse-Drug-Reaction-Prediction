# Modeling 1-RF 代码分析报告

## 项目概述
本项目使用随机森林（Random Forest）模型进行药物不良反应（Adverse Drug Reaction, ADR）预测。代码包含数据预处理、特征工程、模型训练和评估等完整流程。

---

## 代码详细分析

### Cell 0: 工作目录切换
```python
cd /work/farnoush
```
**解释**: 切换到指定工作目录 `/work/farnoush`，用于访问数据文件。

---

### Cell 1: 导入pandas库
```python
import pandas as pd
```
**解释**: 导入pandas库，用于数据处理和分析。pandas是Python中用于数据操作和分析的核心库。

---

### Cell 2: 读取数据
```python
data = pd.read_csv("data.csv")
```
**解释**: 从CSV文件读取数据到pandas DataFrame对象`data`。该文件包含药物不良反应相关的数据。

---

### Cell 3: 提取特定列范围
```python
data2 = data.loc[:, "A0A023W3H0":"W7JWW5"]
```
**解释**: 使用loc方法提取从列"A0A023W3H0"到"W7JWW5"的所有列，这些列名看起来是蛋白质ID（UniProt格式）。`:,:`表示选择所有行和指定列范围。

---

### Cell 4: 查找零和列
```python
columns_with_zero_sum = [col for col in data2.columns if data2[col].sum() == 0]
len(columns_with_zero_sum)
```
**解释**: 
- 第一行：使用列表推导式找出所有列和为0的列名（即该列所有值都为0）
- 第二行：计算这些列的数量
- 这些列对模型没有贡献，应该被移除

---

### Cell 5: 显示零和列
```python
columns_with_zero_sum
```
**解释**: 显示所有列和为0的列名列表，用于检查哪些特征列是无效的。

---

### Cell 6: 移除零列
```python
data = data.loc[:, (data != 0).any(axis=0)]
```
**解释**: 
- `(data != 0).any(axis=0)`: 对每一列检查是否有非零值（axis=0表示按列操作）
- 只保留至少有一个非零值的列
- 移除所有值都为0的列，减少特征维度

---

### Cell 7: 查看数据形状
```python
data.shape
```
**解释**: 返回DataFrame的维度（行数, 列数），用于了解数据规模。

---

### Cell 8: 打印所有列名
```python
for i in data.columns:
    print(i)
```
**解释**: 遍历并打印所有列名，用于了解数据包含哪些特征。输出显示包括：
- 药物ID（drugbank_id）
- 不良反应标签（cardiac failure, vomiting等）
- 人口统计学特征（sex_F, sex_M, age_group_1-5）
- 分子特征（molecular_weight等）
- 蛋白质ID（A0A024R8I1等UniProt格式）

---

### Cell 9: 提取分子特征
```python
molecular_df = data.loc[:, "molecular_weight":"covalent_unit_count"]
```
**解释**: 提取从"molecular_weight"到"covalent_unit_count"的所有列，这些是分子的物理化学特征（如分子量、氢键供体数等）。

---

### Cell 10: K-means聚类 - 轮廓系数分析
```python
from sklearn.metrics import silhouette_score
from sklearn.cluster import KMeans

silhouette_scores = []

# Calculate silhouette score for different numbers of clusters
for i in range(2, 30):
    kmeans = KMeans(n_clusters=i, random_state=42)
    kmeans.fit(molecular_df)
    labels = kmeans.labels_
    silhouette_avg = silhouette_score(molecular_df, labels)
    silhouette_scores.append(silhouette_avg)

# Plot the silhouette scores
plt.plot(range(2, 30), silhouette_scores, marker='o')
plt.title('Silhouette Score for Different Numbers of Clusters')
plt.xlabel('Number of clusters')
plt.ylabel('Silhouette Score')
plt.show()
```
**解释**: 
- **导入模块**: 导入轮廓系数评估函数和K-means聚类算法
- **初始化列表**: 创建空列表存储轮廓系数
- **循环测试**: 对聚类数2到29进行测试
  - `KMeans(n_clusters=i, random_state=42)`: 创建K-means聚类器，设置随机种子保证可重复性
  - `fit()`: 在分子特征数据上训练聚类模型
  - `labels_`: 获取每个样本的聚类标签
  - `silhouette_score()`: 计算轮廓系数，评估聚类质量（值越接近1越好）
- **可视化**: 绘制轮廓系数随聚类数变化的曲线，用于选择最优聚类数

---

### Cell 11: K-means聚类 - 肘部法则
```python
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
wcss =[]
for i in range (1,30):
    kmeans = KMeans (n_clusters = i, init = 'k-means++' , random_state=42)
    kmeans.fit(molecular_df)
    wcss.append(kmeans.inertia_)
plt.plot(range(1,30), wcss)
plt.show()
```
**解释**: 
- **导入库**: 导入matplotlib用于绘图和KMeans
- **初始化列表**: `wcss`存储类内平方和（Within-Cluster Sum of Squares）
- **循环计算**: 对聚类数1到29进行测试
  - `init='k-means++'`: 使用k-means++初始化方法，比随机初始化更优
  - `inertia_`: 获取类内平方和，衡量聚类紧密程度
- **肘部法则**: 绘制wcss曲线，寻找"肘部"点（曲线急剧下降后趋于平缓的点）作为最优聚类数

---

### Cell 12: 基于聚类的数据分割
```python
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=25, random_state=42).fit(molecular_df)
cluster_labels = pd.Series(kmeans.labels_)
tmp = cluster_labels.value_counts()
tmp = tmp / tmp.sum()
tmp = tmp.sample(frac=1, random_state=30).cumsum()
train_clusters = set(tmp[lambda x: x<.80].index)
test_clusters = set(tmp[lambda x: x>=.80].index)
train_mol = molecular_df.iloc[cluster_labels[lambda s: s.map(lambda x: x in train_clusters)].index]
test_mol = molecular_df.iloc[cluster_labels[lambda s: s.map(lambda x: x in test_clusters)].index]

train_test_split = pd.concat([
    train_mol[[]].reset_index().assign(type="train"),
    test_mol[[]].reset_index().assign(type="test"),
])
```
**解释**: 
- **执行聚类**: 使用25个聚类对分子特征进行K-means聚类
- **获取标签**: 将聚类标签转换为pandas Series
- **计算比例**: 
  - `value_counts()`: 统计每个聚类的样本数
  - `tmp / tmp.sum()`: 计算每个聚类的占比
- **随机化并累积**: 
  - `sample(frac=1, random_state=30)`: 随机打乱聚类顺序
  - `cumsum()`: 计算累积和
- **分割聚类**: 
  - `train_clusters`: 累积占比<80%的聚类作为训练集
  - `test_clusters`: 累积占比≥80%的聚类作为测试集
- **提取数据**: 根据聚类标签提取对应的分子特征数据
- **创建分割记录**: 创建包含训练/测试标记的DataFrame

**目的**: 基于分子相似性进行数据分割，确保训练集和测试集在分子特征空间中有不同的分布，更符合实际应用场景。

---

### Cell 13: 标记训练/测试集
```python
data['type'] = 'Neither'

# Check if the values in DataFrame A exist in DataFrame B
mask_B = data.loc[:, "molecular_weight": "covalent_unit_count"].isin(train_mol).all(axis=1)
data.loc[mask_B, 'type'] = 'train'

mask_C = data.loc[:, "molecular_weight": "covalent_unit_count"].isin(test_mol).all(axis=1)
data.loc[mask_C, 'type'] = 'test'
```
**解释**: 
- **初始化**: 为所有样本创建'type'列，初始值为'Neither'
- **创建掩码**: 
  - `mask_B`: 检查每行的分子特征是否完全匹配训练集的分子特征（`all(axis=1)`确保所有列都匹配）
  - `mask_C`: 检查每行的分子特征是否完全匹配测试集的分子特征
- **标记数据**: 根据掩码将对应的行标记为'train'或'test'

---

### Cell 14: 检查类型分布
```python
data["type"].unique()
```
**解释**: 返回'type'列的所有唯一值，用于验证数据分割是否正确（应该包含'train'和'test'）。

---

### Cell 15: 特征标准化
```python
from sklearn.preprocessing import Normalizer

scaler = Normalizer()

# Fit and transform the data
data.loc[:, "molecular_weight":"covalent_unit_count"] = scaler.fit_transform(data.loc[:, "molecular_weight":"covalent_unit_count"])
```
**解释**: 
- **导入Normalizer**: 使用Normalizer进行特征标准化（将每行归一化为单位向量）
- **创建标准化器**: 实例化Normalizer对象
- **标准化**: 对分子特征列进行标准化，使每个样本的分子特征向量长度为1
- **注意**: Normalizer按行归一化，与StandardScaler（按列归一化）不同

---

### Cell 16: 删除冗余特征
```python
data.drop(["sex_F","age_group_1"], axis = 1,  inplace = True)
```
**解释**: 
- **删除列**: 删除"sex_F"和"age_group_1"列
- **axis=1**: 指定删除列（axis=0为行）
- **inplace=True**: 直接修改原DataFrame，不返回新对象
- **原因**: 这些是冗余特征（如sex_F和sex_M是互斥的，age_group_1可能是基准组）

---

### Cell 17: 提取训练集
```python
train = data[data["type"] == "train"]
```
**解释**: 使用布尔索引筛选出所有标记为"train"的行，创建训练集DataFrame。

---

### Cell 18: 提取测试集
```python
test = data[data["type"] == "test"]
```
**解释**: 使用布尔索引筛选出所有标记为"test"的行，创建测试集DataFrame。

---

### Cell 19: 计算测试集比例
```python
test.shape[0]/data.shape[0]
```
**解释**: 计算测试集样本数占总样本数的比例，用于验证数据分割比例是否合理（通常为20-30%）。

---

### Cell 20: 导入机器学习库
```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score, average_precision_score
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, average_precision_score
from sklearn.model_selection import GridSearchCV, cross_val_predict
```
**解释**: 导入所需的库和函数：
- `numpy`: 数值计算
- `pandas`: 数据处理
- `RandomForestClassifier`: 随机森林分类器
- `roc_auc_score`: ROC曲线下面积（AUC）评分
- `average_precision_score`: 平均精度（MAP）评分
- `GridSearchCV`: 网格搜索交叉验证
- `cross_val_predict`: 交叉验证预测
- **注意**: 有重复导入，但不影响功能

---

### Cell 21: 注释标记
```python
# ALL
```
**解释**: 注释标记，表示接下来将使用所有特征进行建模。

---

### Cell 22: 使用所有特征训练随机森林模型
```python
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, average_precision_score

# Assuming train and test DataFrames are already defined
x_train = train.loc[:, 'sex_M':'868']
x_test = test.loc[:, 'sex_M':'868']
y_train = train.loc[:, 'cardiac failure':'vomiting']
y_test = test.loc[:, 'cardiac failure':'vomiting']

# Placeholder for the metrics and feature importances
auc_scores = []
map_scores = []
feature_importances = np.zeros(x_train.shape[1])

# Loop through each label
for label in y_train.columns:
    y_train_label = y_train[label]
    y_test_label = y_test[label]

    # Initialize and train the random forest classifier
    clf = RandomForestClassifier(n_estimators=300, random_state=40)
    clf.fit(x_train, y_train_label)

    # Predict probabilities
    y_pred_prob = clf.predict_proba(x_test)[:, 1]

    # Calculate AUC and MAP
    auc = roc_auc_score(y_test_label, y_pred_prob)
    map_score = average_precision_score(y_test_label, y_pred_prob)

    # Append the scores
    auc_scores.append(auc)
    map_scores.append(map_score)

    # Accumulate feature importances
    feature_importances += clf.feature_importances_

# Calculate average AUC and MAP
average_auc = np.mean(auc_scores)
average_map = np.mean(map_scores)

# Calculate average feature importances across all labels
feature_importances /= len(y_train.columns)

# Calculate average of the top 20 feature importances
top_20_feature_importances = np.sort(feature_importances)[-30:]

# Display the results
print(f'Average AUC: {average_auc}')
print(f'Average MAP: {average_map}')
print(f'Average of Top 20 Feature Importances: {np.mean(top_20_feature_importances)}')

# Optional: if you want to display the names of the top 20 features
top_20_feature_indices = np.argsort(feature_importances)[-20:]
top_20_feature_names = x_train.columns[top_20_feature_indices]
print(f'Top 20 Features: {top_20_feature_names}')
```
**详细解释**:
- **特征提取**: 
  - `x_train/x_test`: 从'sex_M'到'868'的所有特征列（包括人口统计学、分子特征、化学特征、生物特征）
  - `y_train/y_test`: 从'cardiac failure'到'vomiting'的所有不良反应标签（多标签分类）
- **初始化**: 
  - `auc_scores/map_scores`: 存储每个标签的评估指标
  - `feature_importances`: 初始化特征重要性数组
- **多标签循环**: 对每个不良反应标签分别训练模型
  - `RandomForestClassifier(n_estimators=300, random_state=40)`: 创建包含300棵决策树的随机森林
  - `fit()`: 训练模型
  - `predict_proba()[:, 1]`: 获取正类（发生不良反应）的概率
  - `roc_auc_score()`: 计算AUC（衡量分类器区分能力，0.5为随机，1.0为完美）
  - `average_precision_score()`: 计算MAP（考虑精确率和召回率的综合指标）
  - `feature_importances_`: 获取特征重要性并累加
- **结果计算**: 
  - 计算所有标签的平均AUC和MAP
  - 计算平均特征重要性
  - 找出重要性最高的20个特征
- **输出结果**: 打印平均指标和重要特征名称

**输出**: Average AUC: 0.6815, Average MAP: 0.4297

---

### Cell 23: 显示Top 21特征
```python
top_20_feature_indices = np.argsort(feature_importances)[-21:]
top_20_feature_names = x_train.columns[top_20_feature_indices]
print(f'Top 20 Features: {top_20_feature_names}')
```
**解释**: 
- `np.argsort()`: 返回排序后的索引（从小到大）
- `[-21:]`: 取最后21个索引（即重要性最高的21个特征）
- 显示特征名称

---

### Cell 24: 显示Top 20特征重要性值
```python
np.sort(feature_importances)[-20:]
```
**解释**: 对特征重要性数组排序，返回最高的20个重要性值（不包含特征名）。

---

### Cell 25: 查看训练特征
```python
x_train
```
**解释**: 显示训练特征DataFrame，用于检查数据。

---

### Cell 26: 查看最后20个特征重要性
```python
feature_importances[-20:]
```
**解释**: 显示特征重要性数组的最后20个元素（按原始顺序，不是排序后的）。

---

### Cell 27: 查看特定特征重要性
```python
p10635_importance = feature_importances[x_train.columns.get_loc('P10635')]
p10635_importance
```
**解释**: 
- `get_loc()`: 获取列'P10635'的索引位置
- 提取该特征的重要性值
- 用于分析特定蛋白质特征的重要性

---

### Cell 28: 空单元格
```python

```
**解释**: 空单元格，可能用于临时测试或注释。

---

### Cell 29: 注释标记
```python
# Dem
```
**解释**: 注释标记"Dem"（可能是Demographic的缩写），表示接下来使用人口统计学特征。

---

### Cell 30: 仅使用人口统计学特征
```python
x_train= train.loc[:, 'sex_M': 'age_group_5']
y_train= train.loc[:, 'cardiac failure': "vomiting"]
x_test = test.loc[:, 'sex_M': 'age_group_5']
y_test = test.loc[:, 'cardiac failure': "vomiting"]
# Placeholder for the metrics and feature importances
auc_scores = []
map_scores = []
feature_importances = np.zeros(x_train.shape[1])

# Loop through each label
for label in y_train.columns:
    y_train_label = y_train[label]
    y_test_label = y_test[label]

    # Initialize and train the random forest classifier
    clf = RandomForestClassifier(n_estimators=100, random_state=40)
    clf.fit(x_train, y_train_label)

    # Predict probabilities
    y_pred_prob = clf.predict_proba(x_test)[:, 1]

    # Calculate AUC and MAP
    auc = roc_auc_score(y_test_label, y_pred_prob)
    map_score = average_precision_score(y_test_label, y_pred_prob)

    # Append the scores
    auc_scores.append(auc)
    map_scores.append(map_score)

    # Accumulate feature importances
    feature_importances += clf.feature_importances_

# Calculate average AUC and MAP
average_auc = np.mean(auc_scores)
average_map = np.mean(map_scores)

# Calculate average feature importances across all labels
feature_importances /= len(y_train.columns)

# Calculate average of the top 20 feature importances
top_20_feature_importances = np.sort(feature_importances)[-20:]

# Display the results
print(f'Average AUC: {average_auc}')
print(f'Average MAP: {average_map}')
print(f'Average of Top 20 Feature Importances: {np.mean(top_20_feature_importances)}')

# Optional: if you want to display the names of the top 20 features
top_20_feature_indices = np.argsort(feature_importances)[-20:]
top_20_feature_names = x_train.columns[top_20_feature_indices]
print(f'Top 20 Features: {top_20_feature_names}')
```
**解释**: 
- **特征**: 仅使用人口统计学特征（性别和年龄组）
- **模型**: 使用100棵树的随机森林（特征少，树数也减少）
- **目的**: 评估人口统计学特征单独对不良反应预测的贡献

**输出**: Average AUC: 0.5548, Average MAP: 0.3336（性能较低，说明仅人口统计学特征预测能力有限）

---

### Cell 31: 注释标记
```python
# Molecular
```
**解释**: 注释标记，表示接下来使用分子特征。

---

### Cell 32: 仅使用分子特征
```python
x_train= train.loc[:, 'molecular_weight': 'covalent_unit_count']
y_train= train.loc[:, 'cardiac failure': "vomiting"]
x_test = test.loc[:, 'molecular_weight': 'covalent_unit_count']
y_test = test.loc[:, 'cardiac failure': "vomiting"]
# ... (后续代码与Cell 30类似，但使用200棵树)
```
**解释**: 
- **特征**: 仅使用分子物理化学特征（分子量、氢键数、拓扑极性表面积等）
- **模型**: 200棵树的随机森林
- **目的**: 评估分子特征对不良反应预测的贡献

**输出**: Average AUC: 0.5541, Average MAP: 0.3590（性能也较低）

---

### Cell 33: 注释标记
```python
# Chemical
```
**解释**: 注释标记，表示接下来使用化学特征。

---

### Cell 34: 仅使用化学特征
```python
x_train= train.loc[:, "0":"868"]
y_test= test.loc[:, 'cardiac failure': "vomiting"]
# ... (使用200棵树)
```
**解释**: 
- **特征**: 仅使用化学特征（列名"0"到"868"，可能是分子指纹或化学描述符）
- **目的**: 评估化学特征对不良反应预测的贡献

**输出**: Average AUC: 0.6208, Average MAP: 0.4016（性能中等）

---

### Cell 35: 注释标记
```python
# BIO
```
**解释**: 注释标记，表示接下来使用生物特征（蛋白质特征）。

---

### Cell 36: 提取生物特征
```python
x_train= train.loc[:, "A0A024R8I1":"Q9Y6Y9"]
```
**解释**: 提取从"A0A024R8I1"到"Q9Y6Y9"的列，这些是蛋白质ID（UniProt格式），表示药物与蛋白质的相互作用特征。

---

### Cell 37: 查看特征维度
```python
x_train.shape
```
**解释**: 查看生物特征的维度（样本数, 特征数）。

---

### Cell 38: 仅使用生物特征
```python
# ... (使用300棵树)
x_train= train.loc[:, "A0A024R8I1":"Q9Y6Y9"]
# ... (训练和评估代码)
```
**解释**: 
- **特征**: 仅使用蛋白质相互作用特征
- **目的**: 评估生物特征对不良反应预测的贡献

**输出**: Average AUC: 0.6670, Average MAP: 0.4167（性能较好，说明蛋白质特征很重要）

---

### Cell 39: 检查变量
```python
best_model
```
**解释**: 尝试访问`best_model`变量（可能未定义），用于调试。

---

### Cell 40: 注释标记
```python
# BIO DEMO
```
**解释**: 注释标记，表示使用生物特征+人口统计学特征。

---

### Cell 41: 生物特征+人口统计学特征
```python
x_train = pd.concat([train.loc[:, "A0A024R8I1":"Q9Y6Y9"], train.loc[:, "sex_M":"age_group_5"]], axis=1)
# ... (使用300棵树)
```
**解释**: 
- **特征组合**: 使用`pd.concat()`水平拼接生物特征和人口统计学特征
- **axis=1**: 按列拼接
- **目的**: 评估组合特征的预测能力

**输出**: Average AUC: 0.6685, Average MAP: 0.4101（略优于单独使用生物特征）

---

### Cell 42: 检查变量
```python
best_model
```
**解释**: 再次检查变量。

---

### Cell 43: 注释标记
```python
# Chemical + demo
```
**解释**: 注释标记，表示使用化学特征+人口统计学特征。

---

### Cell 44: 化学特征+人口统计学特征
```python
x_train = pd.concat([train.loc[:, "0":"868"], train.loc[:, "sex_M":"age_group_5"]], axis=1)
# ... (使用200棵树)
```
**解释**: 组合化学特征和人口统计学特征。

**输出**: Average AUC: 0.6279, Average MAP: 0.3988

---

### Cell 45: 注释标记
```python
# Molecular +Demo
```
**解释**: 注释标记，表示使用分子特征+人口统计学特征。

---

### Cell 46: 分子特征+人口统计学特征（带网格搜索）
```python
x_train = pd.concat([train.loc[:, 'molecular_weight': 'covalent_unit_count'], train.loc[:, "sex_M":"age_group_5"]], axis=1)
# ...
auc_scores = []
map_scores = []
feature_importances = np.zeros((y_train.shape[1], x_train.shape[1]))

# Define the RandomForestClassifier
rf = RandomForestClassifier(random_state=42)

# Define the parameter grid for GridSearchCV
param_grid = {
    'n_estimators': [50, 200, 800],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

for i in range(y_train.shape[1]):
    # Extract the label column
    y_train_label = y_train.iloc[:, i]
    y_test_label = y_test.iloc[:, i]
    
    # Perform grid search with cross-validation
    grid_search = GridSearchCV(rf, param_grid, scoring='roc_auc', cv=5, n_jobs=-1)
    grid_search.fit(x_train, y_train_label)
    
    # Train the best model from grid search on the entire training data
    best_model = grid_search.best_estimator_
    best_model.fit(x_train, y_train_label)
    
    # Predict probabilities for the positive class
    y_prob = best_model.predict_proba(x_test)[:, 1]
    
    # Calculate AUC
    auc = roc_auc_score(y_test_label, y_prob)
    auc_scores.append(auc)
    
    # Calculate Mean Average Precision (MAP)
    map_score = average_precision_score(y_test_label, y_prob)
    map_scores.append(map_score)
    
    # Get feature importances and add to the total for this target variable
    feature_importances[i, :] = best_model.feature_importances_

# Calculate the average AUC and MAP across all target variables
average_auc = np.mean(auc_scores)
average_map = np.mean(map_scores)

# Calculate the average feature importances across all target variables
average_feature_importances = np.mean(feature_importances, axis=0)

# Print the average AUC and MAP
print(f"\nAverage AUC across all target variables: {average_auc:.4f}")
print(f"Average MAP across all target variables: {average_map:.4f}")

# Identify the top 10 most important features
sorted_indices = np.argsort(average_feature_importances)[::-1]
top_10_features = sorted_indices[:10]

# Print the top 10 most important features
print("\nTop 10 Most Important Features:")
for idx in top_10_features:
    print(f"{x_train.columns[idx]}: {average_feature_importances[idx]:.4f}")
```
**详细解释**:
- **特征组合**: 分子特征+人口统计学特征
- **网格搜索**: 
  - `param_grid`: 定义超参数搜索空间
    - `n_estimators`: 树的数量 [50, 200, 800]
    - `max_depth`: 树的最大深度 [None(无限制), 10, 20]
    - `min_samples_split`: 分裂所需最小样本数 [2, 5, 10]
    - `min_samples_leaf`: 叶节点最小样本数 [1, 2, 4]
  - `GridSearchCV`: 5折交叉验证，使用AUC作为评分
  - `n_jobs=-1`: 使用所有CPU核心并行计算
- **特征重要性存储**: 使用二维数组存储每个标签的特征重要性
- **结果**: 打印平均指标和Top 10特征

---

### Cell 47: 分子特征+人口统计学特征（1000棵树）
```python
# ... (使用1000棵树，无网格搜索)
```
**解释**: 使用更多树（1000）但固定超参数，评估模型性能。

**输出**: Average AUC: 0.5705, Average MAP: 0.3566

---

### Cell 48: 注释标记
```python
# Molecular +bio
```
**解释**: 注释标记，表示使用分子特征+生物特征。

---

### Cell 49: 分子特征+生物特征
```python
x_train = pd.concat([train.loc[:, 'molecular_weight': 'covalent_unit_count'], train.loc[:, "A0A024R8I1":"Q9Y6Y9"]], axis=1)
# ... (使用300棵树)
```
**解释**: 组合分子特征和生物特征。

**输出**: Average AUC: 0.6816, Average MAP: 0.4436（性能很好）

---

### Cell 50: 注释标记
```python
# Chemical molecular
```
**解释**: 注释标记，表示使用化学特征+分子特征。

---

### Cell 51: 化学特征+分子特征
```python
x_train = pd.concat([train.loc[:, 'molecular_weight': 'covalent_unit_count'], train.loc[:, "0":"868"]], axis=1)
# ... (使用300棵树)
```
**解释**: 组合化学特征和分子特征。

**输出**: Average AUC: 0.6180, Average MAP: 0.4046

---

### Cell 52: 注释标记
```python
# Chemical Bio
```
**解释**: 注释标记，表示使用化学特征+生物特征。

---

### Cell 53: 化学特征+生物特征
```python
x_train = pd.concat([train.loc[:, "A0A024R8I1":"Q9Y6Y9"], train.loc[:, "0":"868"]], axis=1)
# ... (使用400棵树)
```
**解释**: 组合化学特征和生物特征。

**输出**: Average AUC: 0.6748, Average MAP: 0.4295

---

### Cell 54: 注释标记
```python
# Chemical + Molecular + Demographic
```
**解释**: 注释标记，表示使用化学+分子+人口统计学特征。

---

### Cell 55: 化学+分子+人口统计学特征
```python
x_train = pd.concat([train.loc[:, "molecular_weight":"868"], train.loc[:, "sex_M":"age_group_5"]], axis=1)
# ... (使用300棵树)
```
**解释**: 组合三种特征类型。

**输出**: Average AUC: 0.6232, Average MAP: 0.4001

---

### Cell 56: 注释标记
```python
# bio + Molecular + Demographic
```
**解释**: 注释标记，表示使用生物+分子+人口统计学特征。

---

### Cell 57: 生物+分子+人口统计学特征
```python
x_train = train.loc[:, "sex_M":"covalent_unit_count"]
# ... (使用300棵树)
```
**解释**: 使用从"sex_M"到"covalent_unit_count"的所有列（包含人口统计学、分子和生物特征）。

**输出**: Average AUC: 0.6913, Average MAP: 0.4356（性能最好）

---

### Cell 58: 注释标记
```python
# bio chemical demo
```
**解释**: 注释标记，表示使用生物+化学+人口统计学特征。

---

### Cell 59: 生物+化学+人口统计学特征
```python
x_train = pd.concat([ train.loc[:, "sex_M":"Q9Y6Y9"], train.loc[:, "0":"868"]], axis=1)
# ... (使用300棵树)
```
**解释**: 组合生物、化学和人口统计学特征。

**输出**: Average AUC: 0.6799, Average MAP: 0.4266

---

### Cell 60: 注释标记
```python
# molecular, chemical, and bio 
```
**解释**: 注释标记，表示使用分子+化学+生物特征（不含人口统计学）。

---

### Cell 61: 分子+化学+生物特征
```python
x_train = train.loc[:, "A0A024R8I1":"868"]
# ... (使用300棵树)
```
**解释**: 组合分子、化学和生物特征。

**输出**: Average AUC: 0.6711, Average MAP: 0.4299

---

### Cell 62: 注释标记
```python
# Feature Importance RF
```
**解释**: 注释标记，表示基于特征重要性进行特征选择。

---

### Cell 63: 使用Top 20特征（包含人口统计学）
```python
x_train = train[['P02768', 'P08183', 'undefined_atom_stereo_count',
       'defined_atom_stereo_count', 'h_bond_donor_count', 'complexity',
       'exact_mass', 'rotatable_bond_count', 'heavy_atom_count',
       'molecular_weight', 'monoisotopic_mass', 'covalent_unit_count', 'tpsa',
       'h_bond_acceptor_count', 'xlogp', 'age_group_2', 'age_group_3',
       'age_group_5', 'age_group_4', 'sex_M']]
# ... (使用400棵树)
```
**解释**: 使用从Cell 22分析得出的Top 20重要特征（包含生物、分子和人口统计学特征）。

**输出**: Average AUC: 0.6112, Average MAP: 0.3820

---

### Cell 64: 使用Top 15特征（不含人口统计学）
```python
x_train = train[['P02768', 'P08183', 'undefined_atom_stereo_count',
       'defined_atom_stereo_count', 'h_bond_donor_count', 'complexity',
       'exact_mass', 'rotatable_bond_count', 'heavy_atom_count',
       'molecular_weight', 'monoisotopic_mass', 'covalent_unit_count', 'tpsa',
       'h_bond_acceptor_count', 'xlogp']]
# ... (使用400棵树)
```
**解释**: 仅使用Top 15非人口统计学特征。

**输出**: Average AUC: 0.5978, Average MAP: 0.3877

---

### Cell 65: 仅使用Top 2生物特征
```python
x_train = train[['P02768', 'P08183']]
# ... (使用400棵树)
```
**解释**: 仅使用最重要的2个生物特征（P02768和P08183）。

**输出**: Average AUC: 0.6357, Average MAP: 0.3790（仅2个特征能达到此性能，说明这两个蛋白质很重要）

---

### Cell 66: 注释标记
```python
# each feature individuially
```
**解释**: 注释标记，表示接下来单独评估每个特征。

---

### Cell 67: 单独评估每个特征（随机森林）
```python
# ... (对每个特征单独训练模型)
for feature in x_train.columns:
    auc_scores = []
    map_scores = []
    
    # Loop through each label
    for label in y_train.columns:
        # Use only the current feature for training and testing
        x_train_feature = x_train[[feature]]
        x_test_feature = x_test[[feature]]
        
        # Initialize and train the random forest classifier
        clf = RandomForestClassifier(n_estimators=10, random_state=60)
        clf.fit(x_train_feature, y_train_label)
        # ... (计算AUC和MAP)
```
**解释**: 
- **目的**: 评估每个特征单独对不良反应预测的贡献
- **方法**: 对每个特征和每个标签组合训练单独的模型
- **树数**: 仅10棵（因为单特征模型简单）
- **输出**: 每个特征的平均AUC和MAP

**结果**: P08183表现最好（AUC: 0.6238），其次是P02768（AUC: 0.5619）

---

### Cell 68: 注释标记
```python
# top 20 USING DL
```
**解释**: 注释标记，表示使用深度学习模型和Top 20特征。

---

### Cell 69: 深度学习模型（Top 20特征）
```python
from sklearn.metrics import roc_auc_score, average_precision_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import AUC
# ...

model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))
model.add(Dropout(0.7))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(30, activation='sigmoid'))  # Sigmoid activation for multi-label classification

# Compile the model with AUC as the metric
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC()])
model.fit(x_train, y_train, epochs=30, batch_size=128, validation_split=0.2)

predictions = model.predict(x_test)

# Calculate AUC for each class
auc_per_class = roc_auc_score(y_test, predictions, average=None)
print(f"AUC per class: {auc_per_class}")

# Calculate macro average AUC
macro_auc = roc_auc_score(y_test, predictions, average='macro')
print(f"Macro AUC: {macro_auc}")

map_per_class = average_precision_score(y_test, predictions, average=None)
print(f"MAP per class: {map_per_class}")

# Calculate macro average MAP
macro_map = average_precision_score(y_test, predictions, average='macro')
print(f"Macro MAP: {macro_map}")
```
**详细解释**:
- **导入库**: 导入TensorFlow/Keras用于深度学习
- **模型架构**: 
  - `Sequential()`: 创建顺序模型
  - `Dense(512, activation='relu')`: 第一层全连接层，512个神经元，ReLU激活
  - `Dropout(0.7)`: Dropout层，70%的神经元随机失活（防止过拟合）
  - `Dense(256)`: 第二层，256个神经元
  - `Dense(128)`: 第三层，128个神经元
  - `Dense(30, activation='sigmoid')`: 输出层，30个神经元对应30个不良反应标签，sigmoid激活（多标签分类）
- **编译**: 
  - `loss='binary_crossentropy'`: 二元交叉熵损失（多标签分类）
  - `optimizer='adam'`: Adam优化器
  - `metrics=[AUC()]`: 使用AUC作为评估指标
- **训练**: 
  - `epochs=30`: 训练30轮
  - `batch_size=128`: 每批128个样本
  - `validation_split=0.2`: 20%训练数据用作验证集
- **预测和评估**: 
  - `predict()`: 对测试集进行预测
  - `roc_auc_score(..., average=None)`: 计算每个类别的AUC
  - `roc_auc_score(..., average='macro')`: 计算宏平均AUC
  - `average_precision_score()`: 计算MAP

---

### Cell 70: 深度学习模型（Top 15特征，不含人口统计学）
```python
# ... (与Cell 69类似，但使用15个特征)
```
**解释**: 使用Top 15非人口统计学特征训练深度学习模型。

---

### Cell 71: 深度学习模型（Top 18特征，不含Top 2生物特征）
```python
# ... (使用除P02768和P08183外的Top特征)
model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(30, activation='sigmoid'))
# ... (50个epochs)
```
**解释**: 
- 使用18个特征（不含Top 2生物特征）
- 增加了一层（32个神经元）
- 训练50轮

---

### Cell 72: 单独评估每个特征（深度学习）
```python
# Define a function to create the model
def create_model(input_shape):
    model = Sequential([
        Dense(512, input_dim=input_shape, activation='relu'),
        Dense(256, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy')
    return model

# Loop through each feature
for feature in x_train.columns:
    auc_scores = []
    map_scores = []
    
    # Loop through each label
    for label in y_train.columns:
        y_train_label = y_train[label]
        y_test_label = y_test[label]
        
        # Use only the current feature for training and testing
        x_train_feature = x_train[[feature]]
        x_test_feature = x_test[[feature]]
        
        # Create and train the neural network model
        model = create_model(input_shape=x_train_feature.shape[1])
        model.fit(x_train_feature, y_train_label, epochs=10, batch_size=32, verbose=0)
        
        # Predict probabilities
        y_pred_prob = model.predict(x_test_feature).flatten()
        
        # Calculate AUC and MAP
        auc = roc_auc_score(y_test_label, y_pred_prob)
        map_score = average_precision_score(y_test_label, y_pred_prob)
        
        # Append the scores
        auc_scores.append(auc)
        map_scores.append(map_score)
    
    # Calculate average AUC and MAP for the current feature
    feature_auc_scores.append(np.mean(auc_scores))
    feature_map_scores.append(np.mean(map_scores))

# Display the results
for feature, auc, map_score in zip(x_train.columns, feature_auc_scores, feature_map_scores):
    print(f'Feature: {feature} - Average AUC: {auc} - Average MAP: {map_score}')
```
**详细解释**:
- **模型创建函数**: 
  - `create_model()`: 定义函数创建神经网络模型
  - 输入层: 512个神经元，ReLU激活
  - 隐藏层: 256个神经元，ReLU激活
  - 输出层: 1个神经元，sigmoid激活（二分类）
  - `Adam(learning_rate=0.001)`: Adam优化器，学习率0.001
- **特征评估循环**: 
  - 对每个特征单独训练深度学习模型
  - `epochs=10`: 训练10轮
  - `batch_size=32`: 每批32个样本
  - `verbose=0`: 不显示训练过程
  - `flatten()`: 将预测结果展平为一维数组
- **目的**: 使用深度学习模型评估每个特征的单独预测能力，与Cell 67的随机森林结果对比

**结果**: P08183表现最好（AUC: 0.6238），与随机森林结果一致

---

### Cell 73: 空单元格
```python

```
**解释**: 空单元格，代码分析结束。

---

## 总结

### 主要发现

1. **最佳特征组合**: 生物特征+分子特征+人口统计学特征（Cell 57）达到最高性能
   - Average AUC: 0.6913
   - Average MAP: 0.4356

2. **重要特征**:
   - **Top 2生物特征**: P02768和P08183（仅使用这两个特征AUC可达0.6357）
   - **分子特征**: undefined_atom_stereo_count, defined_atom_stereo_count, molecular_weight等
   - **人口统计学特征**: age_group_2-5, sex_M

3. **特征类型贡献**:
   - **生物特征（蛋白质）**: 贡献最大（单独使用AUC: 0.6670）
   - **化学特征**: 中等贡献（单独使用AUC: 0.6208）
   - **分子特征**: 较低贡献（单独使用AUC: 0.5541）
   - **人口统计学特征**: 最低贡献（单独使用AUC: 0.5548）

4. **模型对比**:
   - **随机森林**: 在大多数特征组合下表现稳定
   - **深度学习**: 在Top特征上表现良好，但需要更多调优

### 代码结构

1. **数据预处理** (Cell 0-19): 数据加载、清理、特征提取、数据分割
2. **特征工程** (Cell 9-16): 聚类分析、特征标准化、特征选择
3. **模型训练** (Cell 20-65): 多种特征组合的随机森林模型训练
4. **特征重要性分析** (Cell 22-27, 63-67): 识别重要特征
5. **深度学习对比** (Cell 68-72): 使用深度学习模型进行对比实验

### 技术要点

- **基于聚类的数据分割**: 使用K-means聚类确保训练/测试集在分子特征空间中有不同分布
- **多标签分类**: 同时预测30种不同的不良反应
- **特征重要性分析**: 通过累加所有标签的特征重要性识别关键特征
- **超参数调优**: 使用网格搜索优化随机森林参数

---

## 代码质量评估

### 优点
1. 完整的实验流程，从数据预处理到模型评估
2. 系统性地测试了多种特征组合
3. 使用了多种评估指标（AUC和MAP）
4. 进行了特征重要性分析

### 可改进之处
1. 部分代码有重复导入
2. 某些单元格缺少注释
3. 可以添加更多的数据可视化
4. 可以添加交叉验证以提高结果可靠性

---

**报告生成时间**: 2026年2月1日
**代码文件**: Modeling 1-RF.ipynb
**总单元格数**: 73